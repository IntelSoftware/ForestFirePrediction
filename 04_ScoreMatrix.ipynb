{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef6809f-b4e1-4e33-a549-1a00ae11ec84",
   "metadata": {},
   "source": [
    "# Plot scoring positions\n",
    "\n",
    "Use model to inference a new map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d53e-30c5-49c6-9c8b-173a6ae048de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fnmatch\n",
    "#import os\n",
    "#import pathlib\n",
    "#import random\n",
    "#import time\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "#from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from data_loader import (\n",
    "    TRAIN_DIR,\n",
    "    VALID_DIR,\n",
    "    augment_and_save,\n",
    "    data_distribution,\n",
    "    imagenet_stats,\n",
    "    img_transforms,\n",
    "    plot_data_distribution,\n",
    "    show_data,\n",
    ")\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2917d08-7ae8-42b8-b061-d7dd8b1e8212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "237c0d8f-bef7-412a-8261-ef13592045e1",
   "metadata": {},
   "source": [
    "# Specify Model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e456-a8b0-45c5-9991-ff74ea0a5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple = False\n",
    "# epochs = 12\n",
    "# ipx = True \n",
    "# dropout = .5\n",
    "# batch_size = 128\n",
    "# # bc_resnet18_simpleFalse_IPEXTrue_Epochs12_dropout0.4_batch128\n",
    "# model_name = \"ON_resnet18_simpleFalse_IPEXTrue_Epochs40_dropout0.33_batch128\"\n",
    "# #resnet18_simpleFalse_IPEXTrue_Epochs12_dropout0.4_batch128\n",
    "# #model_name = f\"resnet18_simple{simple}_IPEX{ipx}_Epochs{epochs}_dropout{dropout}_batch{batch_size}\"\n",
    "# print(model_name)\n",
    "# model_read = torch.jit.load(f\"models/{model_name}.pt\")\n",
    "\n",
    "# model_read.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b8304-68ca-4b7c-878b-eb1654244574",
   "metadata": {},
   "source": [
    "# Define Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d647d-a813-4db0-bddb-b848e363a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(InFldr, ScoreDict, model):\n",
    "    import torchvision.transforms as transforms\n",
    "    import torch.nn as nn\n",
    "    import glob \n",
    "    model.eval()\n",
    "\n",
    "    scores = []\n",
    "    fns = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(*imagenet_stats),\n",
    "    ])\n",
    "    \n",
    "    for fn in glob.glob(TEST_DIR+'*.png'):\n",
    "        img = Image.open(fn)\n",
    "        img_tensor = transform(img).reshape(1, 3, 1024, 1024)\n",
    "        score = 0\n",
    "        modelCPU = model.to(\"cpu\")\n",
    "        score = np.argmax(torch.softmax( modelCPU(img_tensor).detach(), dim =1).numpy().squeeze())\n",
    "        fns.append(fn)\n",
    "        scores.append(ScoreDict[score])\n",
    "    return (scores, fns)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     model_scripted = torch.jit.script(model.to(\"cpu\"))  # Export to TorchScript\n",
    "#     model_scripted.save(model_save_path)  # Jit Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e45c26-687a-469f-8579-cc8f78e10224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_save_path\n",
    "model_name = f\"models/model_acc_84_device_xpu_lr_0.000214_epochs_20_jit.pt\"\n",
    "print(model_name)\n",
    "\n",
    "model_read = torch.jit.load(model_name)\n",
    "#model_read.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0e043-770a-43cf-877b-435b869d325f",
   "metadata": {},
   "source": [
    "# Scoring individual images with model\n",
    "### Known Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d168f-938d-45f1-b9b9-3d63f5199c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = []\n",
    "ypred = []\n",
    "TEST_DIR =  'data/colorEnhanced/val/Fire/'\n",
    "scoreDict = {0:'Fire', 1:'NoFire'}\n",
    "scores, fns = predict(TEST_DIR, scoreDict, model_read)\n",
    "for score, fn in zip(scores, fns):\n",
    "    print(f\"{score}\\t{fn}\")\n",
    "    if score == 'Fire': \n",
    "        ypred.append(1)\n",
    "    else:\n",
    "        ypred.append(0)\n",
    "    ytrue.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500a614-2253-4efe-b736-9a52db7c4b9b",
   "metadata": {},
   "source": [
    "# Scoring individual images with model\n",
    "### Known NoFire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbc7762-8eba-4749-bbc2-d33b63ca18b8",
   "metadata": {},
   "source": [
    "# Define functions and normalization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d34ef-4afb-4b54-ab5d-2c297cf81b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR =  'data/colorEnhanced/val/NoFire/'\n",
    "scoreDict = {0:'Fire', 1:'NoFire'}\n",
    "scores, fns = predict(TEST_DIR, scoreDict, model_read)\n",
    "for score, fn in zip(scores, fns):\n",
    "    print(f\"{score}\\t{fn}\")\n",
    "    if score == 'Fire': \n",
    "        ypred.append(1)\n",
    "    else:\n",
    "        ypred.append(0)\n",
    "    ytrue.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938f5e23-bd0f-4e32-ac3b-c0b14c115c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fireDict = {0:'Fire', 1:'NoFire'}\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "YTRUE = [fireDict[val] for val in ytrue]\n",
    "YPRED = [fireDict[val] for val in ypred]\n",
    "labels=['Fire', 'NoFire']\n",
    "cm = confusion_matrix(YTRUE, YPRED,  labels=labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500f665-21dc-450e-95d3-66d0cc812d15",
   "metadata": {},
   "source": [
    "## Notices and Disclaimers\n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "\n",
    "No product or component can be absolutely secure. \n",
    "\n",
    "Your costs and results may vary. \n",
    "\n",
    "Â© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcd37-4e5f-4331-ad10-0408523c22f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190c2c8-7648-4507-ad38-ca872d6181b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
