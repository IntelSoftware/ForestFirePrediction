{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26d0ec2-0fc6-4dfd-8f77-f10657db5e8e",
   "metadata": {},
   "source": [
    "# Stable Diffusion: Accelerated\n",
    "\n",
    "requirements:\n",
    "- pip install transformers\n",
    "- pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1d3e5-05f8-4a15-a964-91c8c46e71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class Img2ImgModel:\n",
    "    \"\"\"\n",
    "    This class creates a model for transforming images based on given prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.float16,\n",
    "        optimize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model with the specified parameters.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            device (str, optional): The device to run the model on. Defaults to \"xpu\".\n",
    "            torch_dtype (torch.dtype, optional): The data type to use for the model. Defaults to torch.float16.\n",
    "            optimize (bool, optional): Whether to optimize the model. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.pipeline = self._load_pipeline(model_id_or_path, torch_dtype)\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            print(\"Optimizing the model...\")\n",
    "            self.optimize_pipeline()\n",
    "            print(\n",
    "                \"Optimization completed in {:.2f} seconds.\".format(\n",
    "                    time.time() - start_time\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self, model_id_or_path: str, torch_dtype: torch.dtype\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Load the pipeline for the model.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            torch_dtype (torch.dtype): The data type to use for the model.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The loaded pipeline.\n",
    "        \"\"\"\n",
    "        print(\"Loading the model...\")\n",
    "        pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            model_id_or_path, torch_dtype=torch_dtype\n",
    "        )\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        print(\"Model loaded.\")\n",
    "        return pipeline\n",
    "\n",
    "    def _optimize_pipeline(\n",
    "        self, pipeline: StableDiffusionImg2ImgPipeline\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "\n",
    "        Args:\n",
    "            pipeline (StableDiffusionImg2ImgPipeline): The pipeline to optimize.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The optimized pipeline.\n",
    "        \"\"\"\n",
    "        for attr in dir(pipeline):\n",
    "            if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                setattr(\n",
    "                    pipeline,\n",
    "                    attr,\n",
    "                    ipex.optimize(\n",
    "                        getattr(pipeline, attr).eval(),\n",
    "                        dtype=pipeline.text_encoder.dtype,\n",
    "                        inplace=True,\n",
    "                    ),\n",
    "                 )\n",
    "        return pipeline\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "        \"\"\"\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def get_image_from_url(self, url: str, path: str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Get an image from a URL or from a local path if it exists.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the image.\n",
    "            path (str): The local path of the image.\n",
    "\n",
    "        Returns:\n",
    "            Image.Image: The loaded image.\n",
    "        \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        else:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(\n",
    "                    f\"Failed to download image. Status code: {response.status_code}\"\n",
    "                )\n",
    "            if not response.headers[\"content-type\"].startswith(\"image\"):\n",
    "                raise Exception(\n",
    "                    f\"URL does not point to an image. Content type: {response.headers['content-type']}\"\n",
    "                )\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "            img.save(path)\n",
    "        img = img.resize((768, 512))\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def random_sublist(lst):\n",
    "        sublist = []\n",
    "        for _ in range(random.randint(1, len(lst))):\n",
    "            item = random.choice(lst)\n",
    "            sublist.append(item)\n",
    "        return sublist\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        image_url: str,\n",
    "        class_name: str,\n",
    "        seed_image_identifier: str,\n",
    "        variations: List[str],\n",
    "        num_images: int = 5,\n",
    "        strength: float = 0.75,\n",
    "        guidance_scale: float = 7.5,\n",
    "        save_path: str = \"output\",\n",
    "        seed_path: str = \"intput\",\n",
    "    ) -> List[Image.Image]:\n",
    "        \"\"\"\n",
    "        Generate images based on the provided prompt and variations.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The base prompt for the generation.\n",
    "            image_url (str): The URL of the seed image.\n",
    "            class_name (str): The class of the image (e.g. \"fire\" or \"no_fire\").\n",
    "            seed_image_identifier (str): The identifier of the seed image.\n",
    "            variations (List[str]): The list of variations to apply to the prompt.\n",
    "            num_images (int, optional): The number of images to generate. Defaults to 5.\n",
    "            strength (float, optional): The strength of the transformation. Defaults to 0.75.\n",
    "            guidance_scale (float, optional): The scale of the guidance. Defaults to 7.5.\n",
    "            save_path (str, optional): The path to save the generated images. Defaults to \"output\".\n",
    "            seed_path (str, optional): The path to save the input images. Defaults to \"input\".\n",
    "\n",
    "        Returns:\n",
    "            List[Image.Image]: The list of generated images.\n",
    "        \"\"\"\n",
    "        input_image_path = f\"{seed_path}/{seed_image_identifier}.png\"\n",
    "        init_image = self.get_image_from_url(image_url, input_image_path)\n",
    "        images = []\n",
    "        for i in range(num_images):\n",
    "            variation = variations[i % len(variations)]\n",
    "            final_prompt = f\"{prompt} {variation}\"\n",
    "            image = self.pipeline(\n",
    "                prompt=final_prompt,\n",
    "                image=init_image,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "            ).images\n",
    "            output_image_path = os.path.join(\n",
    "                save_path,\n",
    "                f\"{seed_image_identifier}_{'_'.join(variation.split())}_{i}.png\",\n",
    "            )\n",
    "            image[0].save(output_image_path)\n",
    "            images.append(image)\n",
    "        return images\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "base_prompt = \"A close image to this original satellite image with slight change in location\"\n",
    "fire_variations = [\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes early morning clear skies\",\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes late afternoon clear skies\",\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes mid-day no clouds\",\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes mid-day minimal light sirius cloud cover\",\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes smoky conditions\",\n",
    "    \"vegetation dark green and brown low saturation image mountainous slopes late afternoon minimal light sirius cloud cover\",\n",
    "]\n",
    "no_fire_variations = [\n",
    "    \"early morning with clear skies vegetation bright green vibrant saturation\",\n",
    "    \"no signs of fire vegetation bright green vibrant saturation\",\n",
    "    \"day vegetation bright green vibrant saturation\",\n",
    "    \"late afternoon with clear skies vegetation bright green vibrant saturation\",\n",
    "    \"mid-day with clear skies vegetation bright green vibrant saturation\",\n",
    "    \"with dense vegetation vegetation bright green vibrant saturation\",\n",
    "    \"with sparse vegetation vegetation bright green vibrant saturation\",\n",
    "]\n",
    "\n",
    "image_urls = {\n",
    "    \"fire\": [\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912105_sw_10_h_20160713.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912113_sw_10_h_20160713.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912114_se_10_h_20160806.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912120_ne_10_h_20160713.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_4012355_se_10_h_20160713.png?raw=true\",\n",
    "    ],\n",
    "    \"no_fire\": [\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912045_ne_10_h_20160712.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912057_sw_10_h_20160711.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912142_sw_10_h_20160711.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912343_se_10_h_20160529.png?raw=true\",\n",
    "        \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_4012241_se_10_h_20160712.png?raw=true\",\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d9a23-b542-41ae-8ae6-8bc55622e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5cb55-c354-443c-9415-45ceef11b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimize = True\n",
    "\n",
    "model = Img2ImgModel(model_id, device=\"xpu\", optimize=Optimize)\n",
    "num_images = 2\n",
    "gen_img_count = 0\n",
    "\n",
    "try:\n",
    "    trips = 0\n",
    "    start_time = time.time()\n",
    "    for class_name, urls in image_urls.items():\n",
    "        for url in urls:\n",
    "            seed_image_identifier = os.path.basename(url).split(\".\")[0]\n",
    "            input_dir = f\"./input/{class_name}\"\n",
    "            output_dir = f\"./output/{class_name}\"\n",
    "            os.makedirs(input_dir, exist_ok=True)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            variations = (\n",
    "                fire_variations if class_name == \"fire\" else no_fire_variations\n",
    "            )\n",
    "            model.generate_images(\n",
    "                base_prompt,\n",
    "                url,\n",
    "                class_name,\n",
    "                seed_image_identifier,\n",
    "                variations=variations,\n",
    "                save_path=output_dir,\n",
    "                seed_path=input_dir,\n",
    "                num_images=num_images,\n",
    "            )\n",
    "            gen_img_count += num_images\n",
    "            trips += 1\n",
    "            print(\"inpurt image\",trips)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nUser interrupted image generation...\")\n",
    "finally:\n",
    "    timing[\"xpu IPEX Optimized\"] = time.time() - start_time\n",
    "    print(\n",
    "        f\"Complete generating {gen_img_count} images in {'/'.join(output_dir.split('/')[:-1])} in {time.time() - start_time:.2f} seconds.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8d187-9515-4005-816a-3c2de286a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimize = False\n",
    "\n",
    "model = Img2ImgModel(model_id, device=\"xpu\", optimize=Optimize)\n",
    "num_images = 2\n",
    "gen_img_count = 0\n",
    "\n",
    "try:\n",
    "    trips = 0\n",
    "    start_time = time.time()\n",
    "    for class_name, urls in image_urls.items():\n",
    "        for url in urls:\n",
    "            seed_image_identifier = os.path.basename(url).split(\".\")[0]\n",
    "            input_dir = f\"./input/{class_name}\"\n",
    "            output_dir = f\"./output/{class_name}\"\n",
    "            os.makedirs(input_dir, exist_ok=True)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            variations = (\n",
    "                fire_variations if class_name == \"fire\" else no_fire_variations\n",
    "            )\n",
    "            model.generate_images(\n",
    "                base_prompt,\n",
    "                url,\n",
    "                class_name,\n",
    "                seed_image_identifier,\n",
    "                variations=variations,\n",
    "                save_path=output_dir,\n",
    "                seed_path=input_dir,\n",
    "                num_images=num_images,\n",
    "            )\n",
    "            gen_img_count += num_images\n",
    "            trips += 1\n",
    "            print(\"inpurt image\",trips)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nUser interrupted image generation...\")\n",
    "finally:\n",
    "    timing[\"xpu NOT Optimized\"] = time.time() - start_time\n",
    "    print(\n",
    "        f\"Complete generating {gen_img_count} images in {'/'.join(output_dir.split('/')[:-1])} in {time.time() - start_time:.2f} seconds.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2b286-438a-400e-935f-f8807e94d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimize = True\n",
    "\n",
    "#dtype = torch.float32\n",
    "#dtype = torch.float16\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "model = Img2ImgModel(model_id, device=\"cpu\", optimize=Optimize, torch_dtype = dtype)\n",
    "num_images = 2\n",
    "gen_img_count = 0\n",
    "\n",
    "try:\n",
    "    trips = 0\n",
    "    start_time = time.time()\n",
    "    for class_name, urls in image_urls.items():\n",
    "        for url in urls:\n",
    "            seed_image_identifier = os.path.basename(url).split(\".\")[0]\n",
    "            input_dir = f\"./input/{class_name}\"\n",
    "            output_dir = f\"./output/{class_name}\"\n",
    "            os.makedirs(input_dir, exist_ok=True)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            variations = (\n",
    "                fire_variations if class_name == \"fire\" else no_fire_variations\n",
    "            )\n",
    "            model.generate_images(\n",
    "                base_prompt,\n",
    "                url,\n",
    "                class_name,\n",
    "                seed_image_identifier,\n",
    "                variations=variations,\n",
    "                save_path=output_dir,\n",
    "                seed_path=input_dir,\n",
    "                num_images=num_images,\n",
    "            )\n",
    "            gen_img_count += num_images\n",
    "            trips += 1\n",
    "            print(\"inpurt image\",trips)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nUser interrupted image generation...\")\n",
    "finally:\n",
    "    timing[\"Xeon Optimized\"] = time.time() - start_time\n",
    "    print(\n",
    "        f\"Complete generating {gen_img_count} images in {'/'.join(output_dir.split('/')[:-1])} in {time.time() - start_time:.2f} seconds.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888a751-0d6b-41f2-943e-9ff002074445",
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = dict(sorted(timing.items(), key=lambda item: item[1]))\n",
    "nam = [k for k,v in [t for t in timing.items()]]\n",
    "tim = [v for k,v in [t for t in timing.items()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8f1f2-eb06-4c86-806b-9574a0acc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Time taken to generate images in seconds\",fontsize=12)\n",
    "plt.ylabel(\"Time in seconds\",fontsize=12)\n",
    "plt.xlabel(\"Various optimizations\",fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=-60)\n",
    "plt.bar(x = list(timing.keys()), height= list(timing.values()), align='center',tick_label=list(timing.keys()))\n",
    "print(f\"Acceleration from IPEX {max(tim)/min(tim):.1f}X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a7f51-1bff-452f-b175-d3cdef7254e9",
   "metadata": {},
   "source": [
    "## Notices and Disclaimers\n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "\n",
    "No product or component can be absolutely secure. \n",
    "\n",
    "Your costs and results may vary. \n",
    "\n",
    "Â© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7537e36-e126-4312-bfcc-9994895c8c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597b8e4-f41d-4b78-90d0-0d5d721c3a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c77e4-71eb-4430-bbfe-b97c5fef2481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
