{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26d0ec2-0fc6-4dfd-8f77-f10657db5e8e",
   "metadata": {},
   "source": [
    "# Stable Diffusion: Accelerated\n",
    "\n",
    "requirements:\n",
    "- pip install transformers\n",
    "- pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1d3e5-05f8-4a15-a964-91c8c46e71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "class Img2ImgModel:\n",
    "    \"\"\"\n",
    "    This class creates a model for transforming images based on given prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.float16,\n",
    "        optimize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model with the specified parameters.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            device (str, optional): The device to run the model on. Defaults to \"xpu\".\n",
    "            torch_dtype (torch.dtype, optional): The data type to use for the model. Defaults to torch.float16.\n",
    "            optimize (bool, optional): Whether to optimize the model. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.pipeline = self._load_pipeline(model_id_or_path, torch_dtype)\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            print(\"Optimizing the model...\")\n",
    "            self.optimize_pipeline()\n",
    "            print(\n",
    "                \"Optimization completed in {:.2f} seconds.\".format(\n",
    "                    time.time() - start_time\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self, model_id_or_path: str, torch_dtype: torch.dtype\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Load the pipeline for the model.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            torch_dtype (torch.dtype): The data type to use for the model.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The loaded pipeline.\n",
    "        \"\"\"\n",
    "        print(\"Loading the model...\")\n",
    "        pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            model_id_or_path, torch_dtype=torch_dtype\n",
    "        )\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        print(\"Model loaded.\")\n",
    "        return pipeline\n",
    "\n",
    "    def _optimize_pipeline(\n",
    "        self, pipeline: StableDiffusionImg2ImgPipeline\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "\n",
    "        Args:\n",
    "            pipeline (StableDiffusionImg2ImgPipeline): The pipeline to optimize.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The optimized pipeline.\n",
    "        \"\"\"\n",
    "        for attr in dir(pipeline):\n",
    "            if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                setattr(\n",
    "                    pipeline,\n",
    "                    attr,\n",
    "                    ipex.optimize(\n",
    "                        getattr(pipeline, attr).eval(),\n",
    "                        dtype=pipeline.text_encoder.dtype,\n",
    "                        inplace=True,\n",
    "                    ),\n",
    "                )\n",
    "        return pipeline\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "        \"\"\"\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def get_image_from_url(self, url: str, path: str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Get an image from a URL or from a local path if it exists.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the image.\n",
    "            path (str): The local path of the image.\n",
    "\n",
    "        Returns:\n",
    "            Image.Image: The loaded image.\n",
    "        \"\"\"\n",
    "        if os.path.exists(path):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "        else:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(\n",
    "                    f\"Failed to download image. Status code: {response.status_code}\"\n",
    "                )\n",
    "            if not response.headers[\"content-type\"].startswith(\"image\"):\n",
    "                raise Exception(\n",
    "                    f\"URL does not point to an image. Content type: {response.headers['content-type']}\"\n",
    "                )\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "            img.save(path)\n",
    "        img = img.resize((768, 512))\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def random_sublist(lst):\n",
    "        sublist = []\n",
    "        for _ in range(random.randint(1, len(lst))):\n",
    "            item = random.choice(lst)\n",
    "            sublist.append(item)\n",
    "        return sublist\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        image_url: str,\n",
    "        class_name: str,\n",
    "        seed_image_identifier: str,\n",
    "        variations: List[str],\n",
    "        num_images: int = 5,\n",
    "        strength: float = 0.75,\n",
    "        guidance_scale: float = 7.5,\n",
    "        save_path: str = \"output\",\n",
    "        seed_path: str = \"intput\",\n",
    "    ) -> List[Image.Image]:\n",
    "        \"\"\"\n",
    "        Generate images based on the provided prompt and variations.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The base prompt for the generation.\n",
    "            image_url (str): The URL of the seed image.\n",
    "            class_name (str): The class of the image (e.g. \"fire\" or \"no_fire\").\n",
    "            seed_image_identifier (str): The identifier of the seed image.\n",
    "            variations (List[str]): The list of variations to apply to the prompt.\n",
    "            num_images (int, optional): The number of images to generate. Defaults to 5.\n",
    "            strength (float, optional): The strength of the transformation. Defaults to 0.75.\n",
    "            guidance_scale (float, optional): The scale of the guidance. Defaults to 7.5.\n",
    "            save_path (str, optional): The path to save the generated images. Defaults to \"output\".\n",
    "            seed_path (str, optional): The path to save the input images. Defaults to \"input\".\n",
    "\n",
    "        Returns:\n",
    "            List[Image.Image]: The list of generated images.\n",
    "        \"\"\"\n",
    "        input_image_path = f\"{seed_path}/{seed_image_identifier}.png\"\n",
    "        init_image = self.get_image_from_url(image_url, input_image_path)\n",
    "        images = []\n",
    "        for i in range(num_images):\n",
    "            variation = variations[i % len(variations)]\n",
    "            final_prompt = f\"{prompt} {variation}\"\n",
    "            image = self.pipeline(\n",
    "                prompt=final_prompt,\n",
    "                image=init_image,\n",
    "                strength=strength,\n",
    "                guidance_scale=guidance_scale,\n",
    "            ).images\n",
    "            output_image_path = os.path.join(\n",
    "                save_path,\n",
    "                f\"{seed_image_identifier}_{'_'.join(variation.split())}_{i}.png\",\n",
    "            )\n",
    "            image[0].save(output_image_path)\n",
    "            images.append(image)\n",
    "        return images\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "    base_prompt = \"A close image to this original satellite image with slight change in location\"\n",
    "    fire_variations = [\n",
    "        \"early morning with a wild fire\",\n",
    "        \"late afternoon\",\n",
    "        \"mid-day\",\n",
    "        \"night with wild fire\",\n",
    "        \"smoky conditions\",\n",
    "        \"visible fire lines\",\n",
    "    ]\n",
    "    no_fire_variations = [\n",
    "        \"early morning with clear skies\",\n",
    "        \"no signs of fire\",\n",
    "        \"night\",\n",
    "        \"late afternoon with clear skies\",\n",
    "        \"mid-day with clear skies\",\n",
    "        \"with dense vegetation\",\n",
    "        \"with sparse vegetation\",\n",
    "    ]\n",
    "\n",
    "    image_urls = {\n",
    "        \"fire\": [\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912105_sw_10_h_20160713.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912113_sw_10_h_20160713.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912114_se_10_h_20160806.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_3912120_ne_10_h_20160713.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/Fire/m_4012355_se_10_h_20160713.png?raw=true\",\n",
    "        ],\n",
    "        \"no_fire\": [\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912045_ne_10_h_20160712.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912057_sw_10_h_20160711.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912142_sw_10_h_20160711.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_3912343_se_10_h_20160529.png?raw=true\",\n",
    "            \"https://github.com/rahulunair/ForestFirePrediction/blob/main/data/output/train/NoFire/m_4012241_se_10_h_20160712.png?raw=true\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    model = Img2ImgModel(model_id, device=\"xpu\")\n",
    "    num_images = 5\n",
    "    gen_img_count = 0\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        for class_name, urls in image_urls.items():\n",
    "            for url in urls:\n",
    "                seed_image_identifier = os.path.basename(url).split(\".\")[0]\n",
    "                input_dir = f\"./input/{class_name}\"\n",
    "                output_dir = f\"./output/{class_name}\"\n",
    "                os.makedirs(input_dir, exist_ok=True)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                variations = (\n",
    "                    fire_variations if class_name == \"fire\" else no_fire_variations\n",
    "                )\n",
    "                model.generate_images(\n",
    "                    base_prompt,\n",
    "                    url,\n",
    "                    class_name,\n",
    "                    seed_image_identifier,\n",
    "                    variations=variations,\n",
    "                    save_path=output_dir,\n",
    "                    seed_path=input_dir,\n",
    "                    num_images=num_images,\n",
    "                )\n",
    "                gen_img_count += num_images\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nUser interrupted image generation...\")\n",
    "    finally:\n",
    "        print(\n",
    "            f\"Complete generating {gen_img_count} images in {'/'.join(output_dir.split('/')[:-1])} in {time.time() - start_time:.2f} seconds.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8d187-9515-4005-816a-3c2de286a573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
