{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fa44a6-07af-4996-8290-0314e0c89cbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Model\n",
    "\n",
    "Each green square is roughly 60 square miles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa114f28-c133-4d6b-8270-aabcc6d9dbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 13:32:16,469 - numexpr.utils - INFO - Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-23 13:32:16,471 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/ON_resnet18_simpleFalse_IPEXTrue_Epochs20_dropout0.33_batch128.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=FireFinder\n",
       "  (network): RecursiveScriptModule(\n",
       "    original_name=ResNet\n",
       "    (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "    (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "    (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "    (maxpool): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (layer1): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer2): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer3): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer4): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=_IPEXConv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): RecursiveScriptModule(original_name=AdaptiveAvgPool2d)\n",
       "    (fc): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(original_name=Linear)\n",
       "      (1): RecursiveScriptModule(original_name=ReLU)\n",
       "      (2): RecursiveScriptModule(original_name=Dropout)\n",
       "      (3): RecursiveScriptModule(original_name=Linear)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import intel_extension_for_pytorch as ipex\n",
    "# Import the Intel Extension for PyTorch library, which provides optimizations for Intel architectures\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "# Import the necessary libraries for data visualization and manipulation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Indicate what backbone model was used\n",
    "#scratch_model = models.resnet18(pretrained=True)\n",
    "#num_ftrs = scratch_model.fc.in_features\n",
    "# modify the backbone to have just three predicted classes\n",
    "#classes = 2\n",
    "#scratch_model.fc = nn.Linear(num_ftrs, classes)\n",
    "model_name = \"ON_resnet18_simpleFalse_IPEXTrue_Epochs20_dropout0.33_batch128\"\n",
    "model_path = f\"models/{model_name}.pt\"\n",
    "print(model_path)\n",
    "model_read = torch.jit.load(model_path)\n",
    "# Load the pre-trained model from the specified file path\n",
    "# The `model_name` is used to construct the file path, assuming it has the \".pt\" extension\n",
    "\n",
    "model_read.eval()\n",
    "\n",
    "#indicate the path and filename of output image\n",
    "#map_save = 'data/MoabDinoTrail_ThreeClassBalanced.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e431d98-a5dc-43b2-853a-fe4ef3017b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test/unknown/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Datasets and Dataloaders...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Create training and validation datasets\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: datasets\u001b[38;5;241m.\u001b[39mImageFolder(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, x), data_transforms[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create training and validation dataloaders\u001b[39;00m\n\u001b[1;32m     31\u001b[0m dataloaders_dict \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing Datasets and Dataloaders...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Create training and validation datasets\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x: \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create training and validation dataloaders\u001b[39;00m\n\u001b[1;32m     31\u001b[0m dataloaders_dict \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m~/.conda/envs/openvinopytorch/lib/python3.9/site-packages/torchvision/datasets/folder.py:310\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    304\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m ):\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[0;32m~/.conda/envs/openvinopytorch/lib/python3.9/site-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 145\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[0;32m~/.conda/envs/openvinopytorch/lib/python3.9/site-packages/torchvision/datasets/folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/openvinopytorch/lib/python3.9/site-packages/torchvision/datasets/folder.py:41\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test/unknown/train'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "input_size = 224\n",
    "data_dir = \"data/test/unknown/\"\n",
    "\n",
    "batch_size = 64\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'unknown': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device: {}\".format(device))\n",
    "\n",
    "\n",
    "files = []\n",
    "class_true = []\n",
    "class_pred = []\n",
    "#my_classes = ['Bone', 'NoBone']\n",
    "my_classes = image_datasets['val'].classes\n",
    "\n",
    "green = Image.new('RGBA',(224,224),(0,255,0,60))\n",
    "white = Image.new('RGBA',(224,224),(255,255,255,1))\n",
    "lightGreen = Image.new('RGBA',(224,224),(0,255,0,20))\n",
    "black = Image.new('RGBA',(224,224),(0,0,0,1))\n",
    "\n",
    "\n",
    "def DatasetSizes(dataset_ReadClassChoices):\n",
    "    dataset_sizes = {x: len(dataset_ReadClassChoices[x]) for x in ['unknown']}\n",
    "    return dataset_sizes\n",
    "\n",
    "def scoreSingleImage(ImagePath, model, dataset_classes):\n",
    "    from PIL import Image\n",
    "    import torch.nn.functional as F\n",
    "    from torch.autograd import Variable\n",
    "    model.eval()\n",
    "    #model.to(device)\n",
    "    img = Image.open(ImagePath).convert('RGB') \n",
    "    x_test = data_transforms['val'](img)[:3]   #3 channels in case png bobc\n",
    "    x_test.unsqueeze_(0)  # Add batch dimension\n",
    "    x_test2 = Variable(x_test)\n",
    "    output = model(x_test)\n",
    "    class_names = dataset_classes\n",
    "    predArgmax = torch.argmax(output[0]).numpy()\n",
    "    confidence = F.softmax(output, dim=0)\n",
    "    score = []\n",
    "    score.append( class_names[predArgmax] )\n",
    "    score.append( float(confidence[0][predArgmax]) )\n",
    "    return score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e42fd-f193-4ac2-8164-f01ee07560ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/ThreeClassManualRemove0s/train/2/FragmentsPresent0008.png'\n",
    "scoreSingleImage(filename, scratch_model, my_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c10de-219f-4fc6-bdcb-64e8dd3b7b07",
   "metadata": {},
   "source": [
    "# Score val folder to print metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbb0b2-0d63-4961-8b97-efcf2c51c9f0",
   "metadata": {},
   "source": [
    "### Metrics Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009a5f0-ebba-4d99-9c2d-778c986f5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Violence Class\n",
    "def calc_metrics(tp_rowcol, cm):\n",
    "    # this works only for col 0, row 0 for now \n",
    "    #will troubleshoot other columns later\n",
    "    # so its works for Violence but i have not generalized the cal to accomdate other row,col as the tp\n",
    "\n",
    "    tmp = 0\n",
    "    tp_rowcol = -tp_rowcol\n",
    "    tmp = np.roll(cm, tp_rowcol, axis=1)\n",
    "    cm = np.roll(tmp, tp_rowcol, axis=0)  \n",
    "\n",
    "    L = len(cm)\n",
    "    tp = cm[0][0]\n",
    "    fn = sum(cm[0][1:L])\n",
    "    fp = sum(cm, axis = 0)[0] - tp\n",
    "    ftn = sum(cm, axis = 0) - cm[0]\n",
    "    tn = sum(cm[1:L,1:L])\n",
    "    sensitivity_recall =  tp  / (tp + fn + 0.)\n",
    "    specificity =  tn / (tn + fp + 0.)\n",
    "    precision =  tp / (tp + fp + 0.)\n",
    "    accuracy =  (tp+tn+ 0.)/(tp+fp+fn+tn + 0.)\n",
    "    f1 = 2.0*precision*sensitivity_recall/(precision+sensitivity_recall)\n",
    "    return(accuracy, precision, sensitivity_recall, specificity, f1)\n",
    "def print_metrics(accuracy, precision, sensitivity_recall, specificity, f1):\n",
    "    print ('accuracy: ', accuracy)\n",
    "    print ('sensitivity_recall: ',sensitivity_recall)\n",
    "    print ('specificity: ', specificity)\n",
    "    print ('precision: ', precision)\n",
    "    print ('f1: ', f1)\n",
    "def metricsAsDataframe(accuracy, precision, sensitivity_recall, specificity, f1):\n",
    "    data = [{'metric': 'accuracy', 'Value': accuracy, 'Description': '(tp+tn)/(tp+fp+fn+tn)'},\n",
    "             {'metric': 'precision',  'Value': precision, 'Description': 'tp/(tp+fp)' },\n",
    "             {'metric': 'sensitivity_recall',  'Value': sensitivity_recall, 'Description': 'tp  / (tp + fn)'},\n",
    "             {'metric': 'specificity',  'Value': specificity,  'Description': 'tn / (tn + fp)'},\n",
    "            {'metric': 'F1',  'Value': f1,  'Description': '2*precision*recall/(precision+recall)'}]\n",
    "    dfObj = pd.DataFrame(data, columns=['metric', 'Value', 'Description'])\n",
    "    return dfObj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f3878-8c3b-45b1-bdc8-c42351e3ba71",
   "metadata": {},
   "source": [
    "# Score All Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32929b0-eb18-427a-bc42-0f29b48de0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folders = my_classes\n",
    "files = []\n",
    "class_true = []\n",
    "class_pred = []\n",
    "for fl in folders:\n",
    "    path = data_dir + 'val/' + fl + '/'\n",
    "    for filename in glob.glob(os.path.join(path, '*.png')):\n",
    "        files.append(filename)\n",
    "        try: \n",
    "            pred = scoreSingleImage(filename, scratch_model, my_classes)\n",
    "            class_pred.append(pred[0])\n",
    "            class_true.append(filename.split('/')[-2])\n",
    "        except:\n",
    "            print (\"File not compatible (channels)\", filename)\n",
    "        \n",
    "#[[t, p] for t, p in zip(class_true, class_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00589185-6b43-470a-b45c-a3fe22bf0b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Print Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17855688-77c5-47ba-be05-9da7b99c3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import *\n",
    "import sys\n",
    "from pylab import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = class_true\n",
    "y_pred = class_pred\n",
    "\n",
    "myset = set(y_true)\n",
    "labels = list(myset)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred,  labels=labels)\n",
    "cmd = cm.copy()\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23200297-93c5-42e8-853b-631f652c701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100*np.round(cmd/cmd.sum(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b217493-901c-486d-916b-652680e41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class_true = np.array(class_true)\n",
    "class_pred = np.array(class_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(class_true, class_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af9b5e-47de-4986-a845-948b76fe9437",
   "metadata": {},
   "source": [
    "If you have any issues or want to contribute, please contact our authors:\n",
    "Intel oneAPI Solution Architect\n",
    "- Chesebrough, Bob [bob.chesebrough (at) intel.com]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07ea1e-b1af-4e95-8f63-885f4f75d786",
   "metadata": {},
   "source": [
    "## Notices and Disclaimers\n",
    "\n",
    "Intel technologies may require enabled hardware, software or service activation.\n",
    "\n",
    "No product or component can be absolutely secure. \n",
    "\n",
    "Your costs and results may vary. \n",
    "\n",
    "© Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3ee56-3866-4410-9132-b090247c8cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvinopytorch",
   "language": "python",
   "name": "openvinopytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
